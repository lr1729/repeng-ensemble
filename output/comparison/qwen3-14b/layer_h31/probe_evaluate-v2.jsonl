{"key": "result_0", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9368104312938816, "accuracy_n": 997, "auc": 0.9368104312938816}}
{"key": "result_1", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9617706237424547, "accuracy_n": 994, "auc": 0.9617706237424547}}
{"key": "result_2", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9417085427135679, "accuracy_n": 995, "auc": 0.9417085427135679}}
{"key": "result_3", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9819277108433735, "accuracy_n": 996, "auc": 0.9819277108433735}}
{"key": "result_4", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8036363636363636, "accuracy_n": 275, "auc": 0.8036363636363636}}
{"key": "result_5", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.69, "accuracy_n": 100, "auc": 0.69}}
{"key": "result_6", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5216952573158425, "accuracy_n": 991, "auc": 0.5216952573158425}}
{"key": "result_7", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6172344689378757, "accuracy_n": 499, "auc": 0.6172344689378757}}
{"key": "result_8", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7891566265060241, "accuracy_n": 498, "auc": 0.7891566265060241}}
{"key": "result_9", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9026845637583892, "accuracy_n": 298, "auc": 0.9026845637583892}}
{"key": "result_10", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9559118236472945, "accuracy_n": 499, "auc": 0.9559118236472945}}
{"key": "result_11", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.705, "accuracy_n": 400, "auc": 0.705}}
{"key": "result_12", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_13", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9482758620689655, "accuracy_n": 58, "auc": 0.9482758620689655}}
{"key": "result_14", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9945551436515292, "accuracy_n": 322, "auc": 0.9945551436515292}}
{"key": "result_15", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8577067669172932, "accuracy_n": 292, "auc": 0.8577067669172932}}
{"key": "result_16", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "imdb", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_17", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9348044132397192, "accuracy_n": 997, "auc": 0.9348044132397192}}
{"key": "result_18", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9617706237424547, "accuracy_n": 994, "auc": 0.9617706237424547}}
{"key": "result_19", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9366834170854271, "accuracy_n": 995, "auc": 0.9366834170854271}}
{"key": "result_20", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9819277108433735, "accuracy_n": 996, "auc": 0.9819277108433735}}
{"key": "result_21", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8363636363636363, "accuracy_n": 275, "auc": 0.8363636363636363}}
{"key": "result_22", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7, "accuracy_n": 100, "auc": 0.7}}
{"key": "result_23", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5378405650857719, "accuracy_n": 991, "auc": 0.5378405650857719}}
{"key": "result_24", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5430861723446894, "accuracy_n": 499, "auc": 0.5430861723446894}}
{"key": "result_25", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6947791164658634, "accuracy_n": 498, "auc": 0.6947791164658634}}
{"key": "result_26", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8120805369127517, "accuracy_n": 298, "auc": 0.8120805369127517}}
{"key": "result_27", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9258517034068137, "accuracy_n": 499, "auc": 0.9258517034068137}}
{"key": "result_28", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.455, "accuracy_n": 400, "auc": 0.455}}
{"key": "result_29", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9867986798679867, "accuracy_n": 303, "auc": 0.9867986798679867}}
{"key": "result_30", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6551724137931034, "accuracy_n": 58, "auc": 0.6551724137931034}}
{"key": "result_31", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9723123262279888, "accuracy_n": 322, "auc": 0.9723123262279888}}
{"key": "result_32", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8285714285714286, "accuracy_n": 292, "auc": 0.8285714285714286}}
{"key": "result_33", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "amazon_polarity", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_34", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9338014042126379, "accuracy_n": 997, "auc": 0.9338014042126379}}
{"key": "result_35", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9617706237424547, "accuracy_n": 994, "auc": 0.9617706237424547}}
{"key": "result_36", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9487437185929648, "accuracy_n": 995, "auc": 0.9487437185929648}}
{"key": "result_37", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9859437751004017, "accuracy_n": 996, "auc": 0.9859437751004017}}
{"key": "result_38", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8472727272727273, "accuracy_n": 275, "auc": 0.8472727272727273}}
{"key": "result_39", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.73, "accuracy_n": 100, "auc": 0.73}}
{"key": "result_40", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5035317860746721, "accuracy_n": 991, "auc": 0.5035317860746721}}
{"key": "result_41", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6132264529058116, "accuracy_n": 499, "auc": 0.6132264529058116}}
{"key": "result_42", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7751004016064257, "accuracy_n": 498, "auc": 0.7751004016064257}}
{"key": "result_43", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8791946308724832, "accuracy_n": 298, "auc": 0.8791946308724832}}
{"key": "result_44", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9478957915831663, "accuracy_n": 499, "auc": 0.9478957915831663}}
{"key": "result_45", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.61, "accuracy_n": 400, "auc": 0.61}}
{"key": "result_46", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9900990099009901, "accuracy_n": 303, "auc": 0.9900990099009901}}
{"key": "result_47", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.896551724137931, "accuracy_n": 58, "auc": 0.896551724137931}}
{"key": "result_48", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9930877355576151, "accuracy_n": 322, "auc": 0.9930877355576151}}
{"key": "result_49", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8664943609022556, "accuracy_n": 292, "auc": 0.8664943609022556}}
{"key": "result_50", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "ag_news", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_51", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9348044132397192, "accuracy_n": 997, "auc": 0.9348044132397192}}
{"key": "result_52", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9617706237424547, "accuracy_n": 994, "auc": 0.9617706237424547}}
{"key": "result_53", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9477386934673366, "accuracy_n": 995, "auc": 0.9477386934673366}}
{"key": "result_54", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9889558232931727, "accuracy_n": 996, "auc": 0.9889558232931727}}
{"key": "result_55", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8618181818181818, "accuracy_n": 275, "auc": 0.8618181818181818}}
{"key": "result_56", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.83, "accuracy_n": 100, "auc": 0.83}}
{"key": "result_57", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5640766902119072, "accuracy_n": 991, "auc": 0.5640766902119072}}
{"key": "result_58", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6593186372745491, "accuracy_n": 499, "auc": 0.6593186372745491}}
{"key": "result_59", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7991967871485943, "accuracy_n": 498, "auc": 0.7991967871485943}}
{"key": "result_60", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8926174496644296, "accuracy_n": 298, "auc": 0.8926174496644296}}
{"key": "result_61", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9599198396793587, "accuracy_n": 499, "auc": 0.9599198396793587}}
{"key": "result_62", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6575, "accuracy_n": 400, "auc": 0.6575}}
{"key": "result_63", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_64", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9310344827586207, "accuracy_n": 58, "auc": 0.9310344827586207}}
{"key": "result_65", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9967562557924003, "accuracy_n": 322, "auc": 0.9967562557924003}}
{"key": "result_66", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.918937969924812, "accuracy_n": 292, "auc": 0.918937969924812}}
{"key": "result_67", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "dbpedia_14", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_68", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9388164493480441, "accuracy_n": 997, "auc": 0.9388164493480441}}
{"key": "result_69", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9486921529175051, "accuracy_n": 994, "auc": 0.9486921529175051}}
{"key": "result_70", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9487437185929648, "accuracy_n": 995, "auc": 0.9487437185929648}}
{"key": "result_71", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9859437751004017, "accuracy_n": 996, "auc": 0.9859437751004017}}
{"key": "result_72", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8109090909090909, "accuracy_n": 275, "auc": 0.8109090909090909}}
{"key": "result_73", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.81, "accuracy_n": 100, "auc": 0.81}}
{"key": "result_74", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6992936427850656, "accuracy_n": 991, "auc": 0.6992936427850656}}
{"key": "result_75", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.2845691382765531, "accuracy_n": 499, "auc": 0.2845691382765531}}
{"key": "result_76", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.321285140562249, "accuracy_n": 498, "auc": 0.321285140562249}}
{"key": "result_77", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.3859060402684564, "accuracy_n": 298, "auc": 0.3859060402684564}}
{"key": "result_78", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.37675350701402804, "accuracy_n": 499, "auc": 0.37675350701402804}}
{"key": "result_79", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.235, "accuracy_n": 400, "auc": 0.235}}
{"key": "result_80", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8712871287128713, "accuracy_n": 303, "auc": 0.8712871287128713}}
{"key": "result_81", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 58, "auc": 1.0}}
{"key": "result_82", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9693002780352178, "accuracy_n": 322, "auc": 0.9693002780352178}}
{"key": "result_83", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5522556390977444, "accuracy_n": 292, "auc": 0.5522556390977444}}
{"key": "result_84", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "rte", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8616504854368932, "accuracy_n": 412, "auc": 0.8616504854368932}}
{"key": "result_85", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9368104312938816, "accuracy_n": 997, "auc": 0.9368104312938816}}
{"key": "result_86", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9537223340040242, "accuracy_n": 994, "auc": 0.9537223340040242}}
{"key": "result_87", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9517587939698492, "accuracy_n": 995, "auc": 0.9517587939698492}}
{"key": "result_88", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9789156626506024, "accuracy_n": 996, "auc": 0.9789156626506024}}
{"key": "result_89", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8763636363636363, "accuracy_n": 275, "auc": 0.8763636363636363}}
{"key": "result_90", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.88, "accuracy_n": 100, "auc": 0.88}}
{"key": "result_91", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8506559031281534, "accuracy_n": 991, "auc": 0.8506559031281534}}
{"key": "result_92", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5490981963927856, "accuracy_n": 499, "auc": 0.5490981963927856}}
{"key": "result_93", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7289156626506024, "accuracy_n": 498, "auc": 0.7289156626506024}}
{"key": "result_94", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8087248322147651, "accuracy_n": 298, "auc": 0.8087248322147651}}
{"key": "result_95", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9258517034068137, "accuracy_n": 499, "auc": 0.9258517034068137}}
{"key": "result_96", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7475, "accuracy_n": 400, "auc": 0.7475}}
{"key": "result_97", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7227722772277227, "accuracy_n": 303, "auc": 0.7227722772277227}}
{"key": "result_98", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.603448275862069, "accuracy_n": 58, "auc": 0.603448275862069}}
{"key": "result_99", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5982004942848316, "accuracy_n": 322, "auc": 0.5982004942848316}}
{"key": "result_100", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.581109022556391, "accuracy_n": 292, "auc": 0.581109022556391}}
{"key": "result_101", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "copa", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7524271844660194, "accuracy_n": 412, "auc": 0.7524271844660194}}
{"key": "result_102", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9418254764292878, "accuracy_n": 997, "auc": 0.9418254764292878}}
{"key": "result_103", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.954728370221328, "accuracy_n": 994, "auc": 0.954728370221328}}
{"key": "result_104", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9467336683417086, "accuracy_n": 995, "auc": 0.9467336683417086}}
{"key": "result_105", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9869477911646586, "accuracy_n": 996, "auc": 0.9869477911646586}}
{"key": "result_106", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8618181818181818, "accuracy_n": 275, "auc": 0.8618181818181818}}
{"key": "result_107", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.93, "accuracy_n": 100, "auc": 0.93}}
{"key": "result_108", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8990918264379415, "accuracy_n": 991, "auc": 0.8990918264379415}}
{"key": "result_109", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.47695390781563124, "accuracy_n": 499, "auc": 0.47695390781563124}}
{"key": "result_110", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5341365461847389, "accuracy_n": 498, "auc": 0.5341365461847389}}
{"key": "result_111", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7348993288590604, "accuracy_n": 298, "auc": 0.7348993288590604}}
{"key": "result_112", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8496993987975952, "accuracy_n": 499, "auc": 0.8496993987975952}}
{"key": "result_113", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.635, "accuracy_n": 400, "auc": 0.635}}
{"key": "result_114", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9867986798679867, "accuracy_n": 303, "auc": 0.9867986798679867}}
{"key": "result_115", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9827586206896551, "accuracy_n": 58, "auc": 0.9827586206896551}}
{"key": "result_116", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9915430954587581, "accuracy_n": 322, "auc": 0.9915430954587581}}
{"key": "result_117", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6672462406015036, "accuracy_n": 292, "auc": 0.6672462406015036}}
{"key": "result_118", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "boolq", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9733009708737864, "accuracy_n": 412, "auc": 0.9733009708737864}}
{"key": "result_119", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9378134403209629, "accuracy_n": 997, "auc": 0.9378134403209629}}
{"key": "result_120", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9396378269617707, "accuracy_n": 994, "auc": 0.9396378269617707}}
{"key": "result_121", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9407035175879397, "accuracy_n": 995, "auc": 0.9407035175879397}}
{"key": "result_122", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9889558232931727, "accuracy_n": 996, "auc": 0.9889558232931727}}
{"key": "result_123", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5163636363636364, "accuracy_n": 275, "auc": 0.5163636363636364}}
{"key": "result_124", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.83, "accuracy_n": 100, "auc": 0.83}}
{"key": "result_125", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5782038345105953, "accuracy_n": 991, "auc": 0.5782038345105953}}
{"key": "result_126", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7555110220440882, "accuracy_n": 499, "auc": 0.7555110220440882}}
{"key": "result_127", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.821285140562249, "accuracy_n": 498, "auc": 0.821285140562249}}
{"key": "result_128", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8959731543624161, "accuracy_n": 298, "auc": 0.8959731543624161}}
{"key": "result_129", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9659318637274549, "accuracy_n": 499, "auc": 0.9659318637274549}}
{"key": "result_130", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.83, "accuracy_n": 400, "auc": 0.83}}
{"key": "result_131", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9570957095709571, "accuracy_n": 303, "auc": 0.9570957095709571}}
{"key": "result_132", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5344827586206896, "accuracy_n": 58, "auc": 0.5344827586206896}}
{"key": "result_133", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9827772628977449, "accuracy_n": 322, "auc": 0.9827772628977449}}
{"key": "result_134", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9167293233082707, "accuracy_n": 292, "auc": 0.9167293233082707}}
{"key": "result_135", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "open_book_qa", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_136", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.925777331995988, "accuracy_n": 997, "auc": 0.925777331995988}}
{"key": "result_137", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8903420523138833, "accuracy_n": 994, "auc": 0.8903420523138833}}
{"key": "result_138", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9376884422110553, "accuracy_n": 995, "auc": 0.9376884422110553}}
{"key": "result_139", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9839357429718876, "accuracy_n": 996, "auc": 0.9839357429718876}}
{"key": "result_140", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5672727272727273, "accuracy_n": 275, "auc": 0.5672727272727273}}
{"key": "result_141", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.94, "accuracy_n": 100, "auc": 0.94}}
{"key": "result_142", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5267406659939455, "accuracy_n": 991, "auc": 0.5267406659939455}}
{"key": "result_143", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7855711422845691, "accuracy_n": 499, "auc": 0.7855711422845691}}
{"key": "result_144", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8413654618473896, "accuracy_n": 498, "auc": 0.8413654618473896}}
{"key": "result_145", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.912751677852349, "accuracy_n": 298, "auc": 0.912751677852349}}
{"key": "result_146", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9679358717434869, "accuracy_n": 499, "auc": 0.9679358717434869}}
{"key": "result_147", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8275, "accuracy_n": 400, "auc": 0.8275}}
{"key": "result_148", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8910891089108911, "accuracy_n": 303, "auc": 0.8910891089108911}}
{"key": "result_149", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5172413793103449, "accuracy_n": 58, "auc": 0.5172413793103449}}
{"key": "result_150", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9764828544949027, "accuracy_n": 322, "auc": 0.9764828544949027}}
{"key": "result_151", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8594454887218045, "accuracy_n": 292, "auc": 0.8594454887218045}}
{"key": "result_152", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "race", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_153", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9307923771313942, "accuracy_n": 997, "auc": 0.9307923771313942}}
{"key": "result_154", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9104627766599598, "accuracy_n": 994, "auc": 0.9104627766599598}}
{"key": "result_155", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9396984924623115, "accuracy_n": 995, "auc": 0.9396984924623115}}
{"key": "result_156", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9919678714859438, "accuracy_n": 996, "auc": 0.9919678714859438}}
{"key": "result_157", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5563636363636364, "accuracy_n": 275, "auc": 0.5563636363636364}}
{"key": "result_158", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.92, "accuracy_n": 100, "auc": 0.92}}
{"key": "result_159", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5761856710393541, "accuracy_n": 991, "auc": 0.5761856710393541}}
{"key": "result_160", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7635270541082164, "accuracy_n": 499, "auc": 0.7635270541082164}}
{"key": "result_161", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8373493975903614, "accuracy_n": 498, "auc": 0.8373493975903614}}
{"key": "result_162", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.912751677852349, "accuracy_n": 298, "auc": 0.912751677852349}}
{"key": "result_163", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9679358717434869, "accuracy_n": 499, "auc": 0.9679358717434869}}
{"key": "result_164", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8275, "accuracy_n": 400, "auc": 0.8275}}
{"key": "result_165", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9504950495049505, "accuracy_n": 303, "auc": 0.9504950495049505}}
{"key": "result_166", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5689655172413793, "accuracy_n": 58, "auc": 0.5689655172413793}}
{"key": "result_167", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9866388631448872, "accuracy_n": 322, "auc": 0.9866388631448872}}
{"key": "result_168", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8823778195488723, "accuracy_n": 292, "auc": 0.8823778195488723}}
{"key": "result_169", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_challenge", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_170", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9287863590772317, "accuracy_n": 997, "auc": 0.9287863590772317}}
{"key": "result_171", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9044265593561368, "accuracy_n": 994, "auc": 0.9044265593561368}}
{"key": "result_172", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9407035175879397, "accuracy_n": 995, "auc": 0.9407035175879397}}
{"key": "result_173", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9929718875502008, "accuracy_n": 996, "auc": 0.9929718875502008}}
{"key": "result_174", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5745454545454546, "accuracy_n": 275, "auc": 0.5745454545454546}}
{"key": "result_175", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.93, "accuracy_n": 100, "auc": 0.93}}
{"key": "result_176", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6367305751765893, "accuracy_n": 991, "auc": 0.6367305751765893}}
{"key": "result_177", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7735470941883767, "accuracy_n": 499, "auc": 0.7735470941883767}}
{"key": "result_178", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8413654618473896, "accuracy_n": 498, "auc": 0.8413654618473896}}
{"key": "result_179", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9093959731543624, "accuracy_n": 298, "auc": 0.9093959731543624}}
{"key": "result_180", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9679358717434869, "accuracy_n": 499, "auc": 0.9679358717434869}}
{"key": "result_181", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.825, "accuracy_n": 400, "auc": 0.825}}
{"key": "result_182", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9537953795379538, "accuracy_n": 303, "auc": 0.9537953795379538}}
{"key": "result_183", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5517241379310345, "accuracy_n": 58, "auc": 0.5517241379310345}}
{"key": "result_184", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9913886314488725, "accuracy_n": 322, "auc": 0.9913886314488725}}
{"key": "result_185", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8960996240601503, "accuracy_n": 292, "auc": 0.8960996240601503}}
{"key": "result_186", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "arc_easy", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_187", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9368104312938816, "accuracy_n": 997, "auc": 0.9368104312938816}}
{"key": "result_188", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9004024144869215, "accuracy_n": 994, "auc": 0.9004024144869215}}
{"key": "result_189", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9447236180904522, "accuracy_n": 995, "auc": 0.9447236180904522}}
{"key": "result_190", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9417670682730924, "accuracy_n": 996, "auc": 0.9417670682730924}}
{"key": "result_191", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5890909090909091, "accuracy_n": 275, "auc": 0.5890909090909091}}
{"key": "result_192", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.92, "accuracy_n": 100, "auc": 0.92}}
{"key": "result_193", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.875882946518668, "accuracy_n": 991, "auc": 0.875882946518668}}
{"key": "result_194", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7975951903807615, "accuracy_n": 499, "auc": 0.7975951903807615}}
{"key": "result_195", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8534136546184738, "accuracy_n": 498, "auc": 0.8534136546184738}}
{"key": "result_196", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9060402684563759, "accuracy_n": 298, "auc": 0.9060402684563759}}
{"key": "result_197", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.969939879759519, "accuracy_n": 499, "auc": 0.969939879759519}}
{"key": "result_198", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8375, "accuracy_n": 400, "auc": 0.8375}}
{"key": "result_199", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9570957095709571, "accuracy_n": 303, "auc": 0.9570957095709571}}
{"key": "result_200", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5172413793103449, "accuracy_n": 58, "auc": 0.5172413793103449}}
{"key": "result_201", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9999613839975287, "accuracy_n": 322, "auc": 0.9999613839975287}}
{"key": "result_202", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.93796992481203, "accuracy_n": 292, "auc": 0.93796992481203}}
{"key": "result_203", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "common_sense_qa", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_204", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9458375125376128, "accuracy_n": 997, "auc": 0.9458375125376128}}
{"key": "result_205", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.959758551307847, "accuracy_n": 994, "auc": 0.959758551307847}}
{"key": "result_206", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9256281407035176, "accuracy_n": 995, "auc": 0.9256281407035176}}
{"key": "result_207", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9417670682730924, "accuracy_n": 996, "auc": 0.9417670682730924}}
{"key": "result_208", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6981818181818182, "accuracy_n": 275, "auc": 0.6981818181818182}}
{"key": "result_209", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.58, "accuracy_n": 100, "auc": 0.58}}
{"key": "result_210", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6306760847628657, "accuracy_n": 991, "auc": 0.6306760847628657}}
{"key": "result_211", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.44288577154308617, "accuracy_n": 499, "auc": 0.44288577154308617}}
{"key": "result_212", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5682730923694779, "accuracy_n": 498, "auc": 0.5682730923694779}}
{"key": "result_213", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7416107382550335, "accuracy_n": 298, "auc": 0.7416107382550335}}
{"key": "result_214", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8897795591182365, "accuracy_n": 499, "auc": 0.8897795591182365}}
{"key": "result_215", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.4, "accuracy_n": 400, "auc": 0.4}}
{"key": "result_216", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_217", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9827586206896551, "accuracy_n": 58, "auc": 0.9827586206896551}}
{"key": "result_218", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9930105035526722, "accuracy_n": 322, "auc": 0.9930105035526722}}
{"key": "result_219", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.78125, "accuracy_n": 292, "auc": 0.78125}}
{"key": "result_220", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_221", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9428284854563691, "accuracy_n": 997, "auc": 0.9428284854563691}}
{"key": "result_222", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9607645875251509, "accuracy_n": 994, "auc": 0.9607645875251509}}
{"key": "result_223", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8693467336683417, "accuracy_n": 995, "auc": 0.8693467336683417}}
{"key": "result_224", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8504016064257028, "accuracy_n": 996, "auc": 0.8504016064257028}}
{"key": "result_225", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7854545454545454, "accuracy_n": 275, "auc": 0.7854545454545454}}
{"key": "result_226", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.53, "accuracy_n": 100, "auc": 0.53}}
{"key": "result_227", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.698284561049445, "accuracy_n": 991, "auc": 0.698284561049445}}
{"key": "result_228", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.39478957915831664, "accuracy_n": 499, "auc": 0.39478957915831664}}
{"key": "result_229", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.3714859437751004, "accuracy_n": 498, "auc": 0.3714859437751004}}
{"key": "result_230", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6610738255033557, "accuracy_n": 298, "auc": 0.6610738255033557}}
{"key": "result_231", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8176352705410822, "accuracy_n": 499, "auc": 0.8176352705410822}}
{"key": "result_232", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.2425, "accuracy_n": 400, "auc": 0.2425}}
{"key": "result_233", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_234", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 58, "auc": 1.0}}
{"key": "result_235", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9995752239728143, "accuracy_n": 322, "auc": 0.9995752239728143}}
{"key": "result_236", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7177161654135338, "accuracy_n": 292, "auc": 0.7177161654135338}}
{"key": "result_237", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_238", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9378134403209629, "accuracy_n": 997, "auc": 0.9378134403209629}}
{"key": "result_239", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9466800804828974, "accuracy_n": 994, "auc": 0.9466800804828974}}
{"key": "result_240", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9376884422110553, "accuracy_n": 995, "auc": 0.9376884422110553}}
{"key": "result_241", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9919678714859438, "accuracy_n": 996, "auc": 0.9919678714859438}}
{"key": "result_242", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8618181818181818, "accuracy_n": 275, "auc": 0.8618181818181818}}
{"key": "result_243", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.56, "accuracy_n": 100, "auc": 0.56}}
{"key": "result_244", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7951564076690212, "accuracy_n": 991, "auc": 0.7951564076690212}}
{"key": "result_245", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6733466933867736, "accuracy_n": 499, "auc": 0.6733466933867736}}
{"key": "result_246", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.751004016064257, "accuracy_n": 498, "auc": 0.751004016064257}}
{"key": "result_247", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8825503355704698, "accuracy_n": 298, "auc": 0.8825503355704698}}
{"key": "result_248", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9559118236472945, "accuracy_n": 499, "auc": 0.9559118236472945}}
{"key": "result_249", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7125, "accuracy_n": 400, "auc": 0.7125}}
{"key": "result_250", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_251", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 58, "auc": 1.0}}
{"key": "result_252", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9999227679950572, "accuracy_n": 322, "auc": 0.9999227679950572}}
{"key": "result_253", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8663063909774437, "accuracy_n": 292, "auc": 0.8663063909774437}}
{"key": "result_254", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_255", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8856569709127382, "accuracy_n": 997, "auc": 0.8856569709127382}}
{"key": "result_256", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.937625754527163, "accuracy_n": 994, "auc": 0.937625754527163}}
{"key": "result_257", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8994974874371859, "accuracy_n": 995, "auc": 0.8994974874371859}}
{"key": "result_258", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9718875502008032, "accuracy_n": 996, "auc": 0.9718875502008032}}
{"key": "result_259", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6363636363636364, "accuracy_n": 275, "auc": 0.6363636363636364}}
{"key": "result_260", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.59, "accuracy_n": 100, "auc": 0.59}}
{"key": "result_261", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5196770938446014, "accuracy_n": 991, "auc": 0.5196770938446014}}
{"key": "result_262", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5350701402805611, "accuracy_n": 499, "auc": 0.5350701402805611}}
{"key": "result_263", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6686746987951807, "accuracy_n": 498, "auc": 0.6686746987951807}}
{"key": "result_264", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7986577181208053, "accuracy_n": 298, "auc": 0.7986577181208053}}
{"key": "result_265", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9098196392785571, "accuracy_n": 499, "auc": 0.9098196392785571}}
{"key": "result_266", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.4625, "accuracy_n": 400, "auc": 0.4625}}
{"key": "result_267", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_268", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9655172413793104, "accuracy_n": 58, "auc": 0.9655172413793104}}
{"key": "result_269", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9906549274019153, "accuracy_n": 322, "auc": 0.9906549274019153}}
{"key": "result_270", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9619360902255639, "accuracy_n": 292, "auc": 0.9619360902255639}}
{"key": "result_271", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
{"key": "result_272", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9117352056168505, "accuracy_n": 997, "auc": 0.9117352056168505}}
{"key": "result_273", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9305835010060363, "accuracy_n": 994, "auc": 0.9305835010060363}}
{"key": "result_274", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9417085427135679, "accuracy_n": 995, "auc": 0.9417085427135679}}
{"key": "result_275", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9909638554216867, "accuracy_n": 996, "auc": 0.9909638554216867}}
{"key": "result_276", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7272727272727273, "accuracy_n": 275, "auc": 0.7272727272727273}}
{"key": "result_277", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.53, "accuracy_n": 100, "auc": 0.53}}
{"key": "result_278", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.6044399596367306, "accuracy_n": 991, "auc": 0.6044399596367306}}
{"key": "result_279", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.5771543086172345, "accuracy_n": 499, "auc": 0.5771543086172345}}
{"key": "result_280", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "race", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.7128514056224899, "accuracy_n": 498, "auc": 0.7128514056224899}}
{"key": "result_281", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8456375838926175, "accuracy_n": 298, "auc": 0.8456375838926175}}
{"key": "result_282", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9398797595190381, "accuracy_n": 499, "auc": 0.9398797595190381}}
{"key": "result_283", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.59, "accuracy_n": 400, "auc": 0.59}}
{"key": "result_284", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.9933993399339934, "accuracy_n": 303, "auc": 0.9933993399339934}}
{"key": "result_285", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 58, "auc": 1.0}}
{"key": "result_286", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.995713623725672, "accuracy_n": 322, "auc": 0.995713623725672}}
{"key": "result_287", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 0.8472274436090225, "accuracy_n": 292, "auc": 0.8472274436090225}}
{"key": "result_288", "value": {"llm_id": "Qwen/Qwen3-14B", "train_dataset": "got_larger_than", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h31", "token_idx": -1, "accuracy": 1.0, "accuracy_n": 412, "auc": 1.0}}
