{"key": "result_0", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9304435483870968, "accuracy_n": 992, "auc": 0.9304435483870968}}
{"key": "result_1", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9537223340040242, "accuracy_n": 994, "auc": 0.9537223340040242}}
{"key": "result_2", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.935678391959799, "accuracy_n": 995, "auc": 0.935678391959799}}
{"key": "result_3", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9829145728643216, "accuracy_n": 995, "auc": 0.9829145728643216}}
{"key": "result_4", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7906137184115524, "accuracy_n": 277, "auc": 0.7906137184115524}}
{"key": "result_5", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.65, "accuracy_n": 100, "auc": 0.65}}
{"key": "result_6", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7788944723618091, "accuracy_n": 995, "auc": 0.7788944723618091}}
{"key": "result_7", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6813627254509018, "accuracy_n": 499, "auc": 0.6813627254509018}}
{"key": "result_8", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7349397590361446, "accuracy_n": 498, "auc": 0.7349397590361446}}
{"key": "result_9", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7658862876254181, "accuracy_n": 299, "auc": 0.7658862876254181}}
{"key": "result_10", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9255533199195171, "accuracy_n": 497, "auc": 0.9255533199195171}}
{"key": "result_11", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7814070351758794, "accuracy_n": 398, "auc": 0.7814070351758794}}
{"key": "result_12", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9735973597359736, "accuracy_n": 303, "auc": 0.9735973597359736}}
{"key": "result_13", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9310344827586207, "accuracy_n": 58, "auc": 0.9310344827586207}}
{"key": "result_14", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9261275872721656, "accuracy_n": 322, "auc": 0.9261275872721656}}
{"key": "result_15", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.887593984962406, "accuracy_n": 292, "auc": 0.887593984962406}}
{"key": "result_16", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "imdb", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_17", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9254032258064516, "accuracy_n": 992, "auc": 0.9254032258064516}}
{"key": "result_18", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9507042253521126, "accuracy_n": 994, "auc": 0.9507042253521126}}
{"key": "result_19", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9447236180904522, "accuracy_n": 995, "auc": 0.9447236180904522}}
{"key": "result_20", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9708542713567839, "accuracy_n": 995, "auc": 0.9708542713567839}}
{"key": "result_21", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8086642599277978, "accuracy_n": 277, "auc": 0.8086642599277978}}
{"key": "result_22", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.52, "accuracy_n": 100, "auc": 0.52}}
{"key": "result_23", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7608040201005025, "accuracy_n": 995, "auc": 0.7608040201005025}}
{"key": "result_24", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6693386773547094, "accuracy_n": 499, "auc": 0.6693386773547094}}
{"key": "result_25", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7188755020080321, "accuracy_n": 498, "auc": 0.7188755020080321}}
{"key": "result_26", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7591973244147158, "accuracy_n": 299, "auc": 0.7591973244147158}}
{"key": "result_27", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9235412474849095, "accuracy_n": 497, "auc": 0.9235412474849095}}
{"key": "result_28", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7361809045226131, "accuracy_n": 398, "auc": 0.7361809045226131}}
{"key": "result_29", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9702970297029703, "accuracy_n": 303, "auc": 0.9702970297029703}}
{"key": "result_30", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8620689655172413, "accuracy_n": 58, "auc": 0.8620689655172413}}
{"key": "result_31", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.892840593141798, "accuracy_n": 322, "auc": 0.892840593141798}}
{"key": "result_32", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8406015037593985, "accuracy_n": 292, "auc": 0.8406015037593985}}
{"key": "result_33", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "amazon_polarity", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_34", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9264112903225806, "accuracy_n": 992, "auc": 0.9264112903225806}}
{"key": "result_35", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9507042253521126, "accuracy_n": 994, "auc": 0.9507042253521126}}
{"key": "result_36", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9396984924623115, "accuracy_n": 995, "auc": 0.9396984924623115}}
{"key": "result_37", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9819095477386934, "accuracy_n": 995, "auc": 0.9819095477386934}}
{"key": "result_38", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8231046931407943, "accuracy_n": 277, "auc": 0.8231046931407943}}
{"key": "result_39", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.57, "accuracy_n": 100, "auc": 0.57}}
{"key": "result_40", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7919597989949749, "accuracy_n": 995, "auc": 0.7919597989949749}}
{"key": "result_41", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6292585170340681, "accuracy_n": 499, "auc": 0.6292585170340681}}
{"key": "result_42", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6465863453815262, "accuracy_n": 498, "auc": 0.6465863453815262}}
{"key": "result_43", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.725752508361204, "accuracy_n": 299, "auc": 0.725752508361204}}
{"key": "result_44", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9014084507042254, "accuracy_n": 497, "auc": 0.9014084507042254}}
{"key": "result_45", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6859296482412061, "accuracy_n": 398, "auc": 0.6859296482412061}}
{"key": "result_46", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9702970297029703, "accuracy_n": 303, "auc": 0.9702970297029703}}
{"key": "result_47", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8103448275862069, "accuracy_n": 58, "auc": 0.8103448275862069}}
{"key": "result_48", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8871254247760272, "accuracy_n": 322, "auc": 0.8871254247760272}}
{"key": "result_49", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8351973684210526, "accuracy_n": 292, "auc": 0.8351973684210526}}
{"key": "result_50", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "ag_news", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_51", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9264112903225806, "accuracy_n": 992, "auc": 0.9264112903225806}}
{"key": "result_52", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9537223340040242, "accuracy_n": 994, "auc": 0.9537223340040242}}
{"key": "result_53", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9336683417085427, "accuracy_n": 995, "auc": 0.9336683417085427}}
{"key": "result_54", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9899497487437185, "accuracy_n": 995, "auc": 0.9899497487437185}}
{"key": "result_55", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8303249097472925, "accuracy_n": 277, "auc": 0.8303249097472925}}
{"key": "result_56", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.61, "accuracy_n": 100, "auc": 0.61}}
{"key": "result_57", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.792964824120603, "accuracy_n": 995, "auc": 0.792964824120603}}
{"key": "result_58", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6693386773547094, "accuracy_n": 499, "auc": 0.6693386773547094}}
{"key": "result_59", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7168674698795181, "accuracy_n": 498, "auc": 0.7168674698795181}}
{"key": "result_60", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7625418060200669, "accuracy_n": 299, "auc": 0.7625418060200669}}
{"key": "result_61", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9134808853118712, "accuracy_n": 497, "auc": 0.9134808853118712}}
{"key": "result_62", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7487437185929648, "accuracy_n": 398, "auc": 0.7487437185929648}}
{"key": "result_63", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.966996699669967, "accuracy_n": 303, "auc": 0.966996699669967}}
{"key": "result_64", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8448275862068966, "accuracy_n": 58, "auc": 0.8448275862068966}}
{"key": "result_65", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9260503552672228, "accuracy_n": 322, "auc": 0.9260503552672228}}
{"key": "result_66", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8643796992481203, "accuracy_n": 292, "auc": 0.8643796992481203}}
{"key": "result_67", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "dbpedia_14", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_68", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9243951612903226, "accuracy_n": 992, "auc": 0.9243951612903226}}
{"key": "result_69", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9517102615694165, "accuracy_n": 994, "auc": 0.9517102615694165}}
{"key": "result_70", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9487437185929648, "accuracy_n": 995, "auc": 0.9487437185929648}}
{"key": "result_71", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9487437185929648, "accuracy_n": 995, "auc": 0.9487437185929648}}
{"key": "result_72", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7292418772563177, "accuracy_n": 277, "auc": 0.7292418772563177}}
{"key": "result_73", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.51, "accuracy_n": 100, "auc": 0.51}}
{"key": "result_74", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7226130653266332, "accuracy_n": 995, "auc": 0.7226130653266332}}
{"key": "result_75", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.5971943887775552, "accuracy_n": 499, "auc": 0.5971943887775552}}
{"key": "result_76", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6867469879518072, "accuracy_n": 498, "auc": 0.6867469879518072}}
{"key": "result_77", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6923076923076923, "accuracy_n": 299, "auc": 0.6923076923076923}}
{"key": "result_78", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8913480885311871, "accuracy_n": 497, "auc": 0.8913480885311871}}
{"key": "result_79", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7613065326633166, "accuracy_n": 398, "auc": 0.7613065326633166}}
{"key": "result_80", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6105610561056105, "accuracy_n": 303, "auc": 0.6105610561056105}}
{"key": "result_81", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7241379310344828, "accuracy_n": 58, "auc": 0.7241379310344828}}
{"key": "result_82", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9371717639789929, "accuracy_n": 322, "auc": 0.9371717639789929}}
{"key": "result_83", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8829887218045113, "accuracy_n": 292, "auc": 0.8829887218045113}}
{"key": "result_84", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "rte", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9344660194174758, "accuracy_n": 412, "auc": 0.9344660194174758}}
{"key": "result_85", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9274193548387096, "accuracy_n": 992, "auc": 0.9274193548387096}}
{"key": "result_86", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9446680080482898, "accuracy_n": 994, "auc": 0.9446680080482898}}
{"key": "result_87", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8834170854271357, "accuracy_n": 995, "auc": 0.8834170854271357}}
{"key": "result_88", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.949748743718593, "accuracy_n": 995, "auc": 0.949748743718593}}
{"key": "result_89", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8375451263537906, "accuracy_n": 277, "auc": 0.8375451263537906}}
{"key": "result_90", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.71, "accuracy_n": 100, "auc": 0.71}}
{"key": "result_91", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8160804020100503, "accuracy_n": 995, "auc": 0.8160804020100503}}
{"key": "result_92", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6072144288577155, "accuracy_n": 499, "auc": 0.6072144288577155}}
{"key": "result_93", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6947791164658634, "accuracy_n": 498, "auc": 0.6947791164658634}}
{"key": "result_94", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.725752508361204, "accuracy_n": 299, "auc": 0.725752508361204}}
{"key": "result_95", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8933601609657947, "accuracy_n": 497, "auc": 0.8933601609657947}}
{"key": "result_96", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7613065326633166, "accuracy_n": 398, "auc": 0.7613065326633166}}
{"key": "result_97", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7293729372937293, "accuracy_n": 303, "auc": 0.7293729372937293}}
{"key": "result_98", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6724137931034483, "accuracy_n": 58, "auc": 0.6724137931034483}}
{"key": "result_99", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7967639789928946, "accuracy_n": 322, "auc": 0.7967639789928946}}
{"key": "result_100", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6895206766917293, "accuracy_n": 292, "auc": 0.6895206766917293}}
{"key": "result_101", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "copa", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8228155339805825, "accuracy_n": 412, "auc": 0.8228155339805825}}
{"key": "result_102", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9193548387096774, "accuracy_n": 992, "auc": 0.9193548387096774}}
{"key": "result_103", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9527162977867203, "accuracy_n": 994, "auc": 0.9527162977867203}}
{"key": "result_104", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9437185929648241, "accuracy_n": 995, "auc": 0.9437185929648241}}
{"key": "result_105", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9718592964824121, "accuracy_n": 995, "auc": 0.9718592964824121}}
{"key": "result_106", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8303249097472925, "accuracy_n": 277, "auc": 0.8303249097472925}}
{"key": "result_107", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.71, "accuracy_n": 100, "auc": 0.71}}
{"key": "result_108", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8351758793969849, "accuracy_n": 995, "auc": 0.8351758793969849}}
{"key": "result_109", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6332665330661322, "accuracy_n": 499, "auc": 0.6332665330661322}}
{"key": "result_110", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.748995983935743, "accuracy_n": 498, "auc": 0.748995983935743}}
{"key": "result_111", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7792642140468228, "accuracy_n": 299, "auc": 0.7792642140468228}}
{"key": "result_112", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.93158953722334, "accuracy_n": 497, "auc": 0.93158953722334}}
{"key": "result_113", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7839195979899497, "accuracy_n": 398, "auc": 0.7839195979899497}}
{"key": "result_114", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9900990099009901, "accuracy_n": 303, "auc": 0.9900990099009901}}
{"key": "result_115", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8103448275862069, "accuracy_n": 58, "auc": 0.8103448275862069}}
{"key": "result_116", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9523478529502626, "accuracy_n": 322, "auc": 0.9523478529502626}}
{"key": "result_117", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8960526315789473, "accuracy_n": 292, "auc": 0.8960526315789473}}
{"key": "result_118", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "boolq", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_119", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9213709677419355, "accuracy_n": 992, "auc": 0.9213709677419355}}
{"key": "result_120", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9517102615694165, "accuracy_n": 994, "auc": 0.9517102615694165}}
{"key": "result_121", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7748743718592965, "accuracy_n": 995, "auc": 0.7748743718592965}}
{"key": "result_122", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9738693467336683, "accuracy_n": 995, "auc": 0.9738693467336683}}
{"key": "result_123", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7833935018050542, "accuracy_n": 277, "auc": 0.7833935018050542}}
{"key": "result_124", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.79, "accuracy_n": 100, "auc": 0.79}}
{"key": "result_125", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8331658291457287, "accuracy_n": 995, "auc": 0.8331658291457287}}
{"key": "result_126", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7314629258517034, "accuracy_n": 499, "auc": 0.7314629258517034}}
{"key": "result_127", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7610441767068273, "accuracy_n": 498, "auc": 0.7610441767068273}}
{"key": "result_128", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7959866220735786, "accuracy_n": 299, "auc": 0.7959866220735786}}
{"key": "result_129", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9396378269617707, "accuracy_n": 497, "auc": 0.9396378269617707}}
{"key": "result_130", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7864321608040201, "accuracy_n": 398, "auc": 0.7864321608040201}}
{"key": "result_131", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.966996699669967, "accuracy_n": 303, "auc": 0.966996699669967}}
{"key": "result_132", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7931034482758621, "accuracy_n": 58, "auc": 0.7931034482758621}}
{"key": "result_133", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9580630213160334, "accuracy_n": 322, "auc": 0.9580630213160334}}
{"key": "result_134", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8809680451127819, "accuracy_n": 292, "auc": 0.8809680451127819}}
{"key": "result_135", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "open_book_qa", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_136", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9354838709677419, "accuracy_n": 992, "auc": 0.9354838709677419}}
{"key": "result_137", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9476861167002012, "accuracy_n": 994, "auc": 0.9476861167002012}}
{"key": "result_138", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7396984924623116, "accuracy_n": 995, "auc": 0.7396984924623116}}
{"key": "result_139", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9025125628140703, "accuracy_n": 995, "auc": 0.9025125628140703}}
{"key": "result_140", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7833935018050542, "accuracy_n": 277, "auc": 0.7833935018050542}}
{"key": "result_141", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8, "accuracy_n": 100, "auc": 0.8}}
{"key": "result_142", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8462311557788945, "accuracy_n": 995, "auc": 0.8462311557788945}}
{"key": "result_143", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7334669338677354, "accuracy_n": 499, "auc": 0.7334669338677354}}
{"key": "result_144", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7610441767068273, "accuracy_n": 498, "auc": 0.7610441767068273}}
{"key": "result_145", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7926421404682275, "accuracy_n": 299, "auc": 0.7926421404682275}}
{"key": "result_146", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9456740442655935, "accuracy_n": 497, "auc": 0.9456740442655935}}
{"key": "result_147", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7713567839195979, "accuracy_n": 398, "auc": 0.7713567839195979}}
{"key": "result_148", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9735973597359736, "accuracy_n": 303, "auc": 0.9735973597359736}}
{"key": "result_149", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8103448275862069, "accuracy_n": 58, "auc": 0.8103448275862069}}
{"key": "result_150", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9207599629286376, "accuracy_n": 322, "auc": 0.9207599629286376}}
{"key": "result_151", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.855592105263158, "accuracy_n": 292, "auc": 0.855592105263158}}
{"key": "result_152", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "race", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_153", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9304435483870968, "accuracy_n": 992, "auc": 0.9304435483870968}}
{"key": "result_154", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9557344064386318, "accuracy_n": 994, "auc": 0.9557344064386318}}
{"key": "result_155", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8321608040201005, "accuracy_n": 995, "auc": 0.8321608040201005}}
{"key": "result_156", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9487437185929648, "accuracy_n": 995, "auc": 0.9487437185929648}}
{"key": "result_157", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7833935018050542, "accuracy_n": 277, "auc": 0.7833935018050542}}
{"key": "result_158", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.85, "accuracy_n": 100, "auc": 0.85}}
{"key": "result_159", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8522613065326633, "accuracy_n": 995, "auc": 0.8522613065326633}}
{"key": "result_160", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7294589178356713, "accuracy_n": 499, "auc": 0.7294589178356713}}
{"key": "result_161", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7590361445783133, "accuracy_n": 498, "auc": 0.7590361445783133}}
{"key": "result_162", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7892976588628763, "accuracy_n": 299, "auc": 0.7892976588628763}}
{"key": "result_163", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9476861167002012, "accuracy_n": 497, "auc": 0.9476861167002012}}
{"key": "result_164", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7788944723618091, "accuracy_n": 398, "auc": 0.7788944723618091}}
{"key": "result_165", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9273927392739274, "accuracy_n": 303, "auc": 0.9273927392739274}}
{"key": "result_166", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8103448275862069, "accuracy_n": 58, "auc": 0.8103448275862069}}
{"key": "result_167", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9392956441149212, "accuracy_n": 322, "auc": 0.9392956441149212}}
{"key": "result_168", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.862781954887218, "accuracy_n": 292, "auc": 0.862781954887218}}
{"key": "result_169", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_challenge", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_170", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9314516129032258, "accuracy_n": 992, "auc": 0.9314516129032258}}
{"key": "result_171", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9537223340040242, "accuracy_n": 994, "auc": 0.9537223340040242}}
{"key": "result_172", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8592964824120602, "accuracy_n": 995, "auc": 0.8592964824120602}}
{"key": "result_173", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9256281407035176, "accuracy_n": 995, "auc": 0.9256281407035176}}
{"key": "result_174", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7725631768953068, "accuracy_n": 277, "auc": 0.7725631768953068}}
{"key": "result_175", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.83, "accuracy_n": 100, "auc": 0.83}}
{"key": "result_176", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8492462311557789, "accuracy_n": 995, "auc": 0.8492462311557789}}
{"key": "result_177", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7274549098196392, "accuracy_n": 499, "auc": 0.7274549098196392}}
{"key": "result_178", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7630522088353414, "accuracy_n": 498, "auc": 0.7630522088353414}}
{"key": "result_179", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7892976588628763, "accuracy_n": 299, "auc": 0.7892976588628763}}
{"key": "result_180", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9476861167002012, "accuracy_n": 497, "auc": 0.9476861167002012}}
{"key": "result_181", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7713567839195979, "accuracy_n": 398, "auc": 0.7713567839195979}}
{"key": "result_182", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9306930693069307, "accuracy_n": 303, "auc": 0.9306930693069307}}
{"key": "result_183", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8103448275862069, "accuracy_n": 58, "auc": 0.8103448275862069}}
{"key": "result_184", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9338894037689218, "accuracy_n": 322, "auc": 0.9338894037689218}}
{"key": "result_185", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8652725563909774, "accuracy_n": 292, "auc": 0.8652725563909774}}
{"key": "result_186", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "arc_easy", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_187", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.936491935483871, "accuracy_n": 992, "auc": 0.936491935483871}}
{"key": "result_188", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9476861167002012, "accuracy_n": 994, "auc": 0.9476861167002012}}
{"key": "result_189", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8221105527638191, "accuracy_n": 995, "auc": 0.8221105527638191}}
{"key": "result_190", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8633165829145729, "accuracy_n": 995, "auc": 0.8633165829145729}}
{"key": "result_191", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8194945848375451, "accuracy_n": 277, "auc": 0.8194945848375451}}
{"key": "result_192", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.83, "accuracy_n": 100, "auc": 0.83}}
{"key": "result_193", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8502512562814071, "accuracy_n": 995, "auc": 0.8502512562814071}}
{"key": "result_194", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7394789579158316, "accuracy_n": 499, "auc": 0.7394789579158316}}
{"key": "result_195", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7610441767068273, "accuracy_n": 498, "auc": 0.7610441767068273}}
{"key": "result_196", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7926421404682275, "accuracy_n": 299, "auc": 0.7926421404682275}}
{"key": "result_197", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9476861167002012, "accuracy_n": 497, "auc": 0.9476861167002012}}
{"key": "result_198", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7788944723618091, "accuracy_n": 398, "auc": 0.7788944723618091}}
{"key": "result_199", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9801980198019802, "accuracy_n": 303, "auc": 0.9801980198019802}}
{"key": "result_200", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8620689655172413, "accuracy_n": 58, "auc": 0.8620689655172413}}
{"key": "result_201", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9491813407476059, "accuracy_n": 322, "auc": 0.9491813407476059}}
{"key": "result_202", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8803101503759398, "accuracy_n": 292, "auc": 0.8803101503759398}}
{"key": "result_203", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "common_sense_qa", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_204", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9133064516129032, "accuracy_n": 992, "auc": 0.9133064516129032}}
{"key": "result_205", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9426559356136821, "accuracy_n": 994, "auc": 0.9426559356136821}}
{"key": "result_206", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8532663316582915, "accuracy_n": 995, "auc": 0.8532663316582915}}
{"key": "result_207", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.992964824120603, "accuracy_n": 995, "auc": 0.992964824120603}}
{"key": "result_208", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8194945848375451, "accuracy_n": 277, "auc": 0.8194945848375451}}
{"key": "result_209", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6, "accuracy_n": 100, "auc": 0.6}}
{"key": "result_210", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.807035175879397, "accuracy_n": 995, "auc": 0.807035175879397}}
{"key": "result_211", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6773547094188377, "accuracy_n": 499, "auc": 0.6773547094188377}}
{"key": "result_212", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7188755020080321, "accuracy_n": 498, "auc": 0.7188755020080321}}
{"key": "result_213", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7792642140468228, "accuracy_n": 299, "auc": 0.7792642140468228}}
{"key": "result_214", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9094567404426559, "accuracy_n": 497, "auc": 0.9094567404426559}}
{"key": "result_215", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7512562814070352, "accuracy_n": 398, "auc": 0.7512562814070352}}
{"key": "result_216", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9900990099009901, "accuracy_n": 303, "auc": 0.9900990099009901}}
{"key": "result_217", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8793103448275862, "accuracy_n": 58, "auc": 0.8793103448275862}}
{"key": "result_218", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9702270620945319, "accuracy_n": 322, "auc": 0.9702270620945319}}
{"key": "result_219", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8388157894736842, "accuracy_n": 292, "auc": 0.8388157894736842}}
{"key": "result_220", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_221", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9133064516129032, "accuracy_n": 992, "auc": 0.9133064516129032}}
{"key": "result_222", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8410462776659959, "accuracy_n": 994, "auc": 0.8410462776659959}}
{"key": "result_223", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7407035175879397, "accuracy_n": 995, "auc": 0.7407035175879397}}
{"key": "result_224", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6321608040201006, "accuracy_n": 995, "auc": 0.6321608040201006}}
{"key": "result_225", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7472924187725631, "accuracy_n": 277, "auc": 0.7472924187725631}}
{"key": "result_226", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.61, "accuracy_n": 100, "auc": 0.61}}
{"key": "result_227", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8261306532663316, "accuracy_n": 995, "auc": 0.8261306532663316}}
{"key": "result_228", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6312625250501002, "accuracy_n": 499, "auc": 0.6312625250501002}}
{"key": "result_229", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.678714859437751, "accuracy_n": 498, "auc": 0.678714859437751}}
{"key": "result_230", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7558528428093646, "accuracy_n": 299, "auc": 0.7558528428093646}}
{"key": "result_231", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9275653923541247, "accuracy_n": 497, "auc": 0.9275653923541247}}
{"key": "result_232", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7311557788944724, "accuracy_n": 398, "auc": 0.7311557788944724}}
{"key": "result_233", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9834983498349835, "accuracy_n": 303, "auc": 0.9834983498349835}}
{"key": "result_234", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.896551724137931, "accuracy_n": 58, "auc": 0.896551724137931}}
{"key": "result_235", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.96231078158789, "accuracy_n": 322, "auc": 0.96231078158789}}
{"key": "result_236", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7700187969924813, "accuracy_n": 292, "auc": 0.7700187969924813}}
{"key": "result_237", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_sp_en_trans", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_238", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8881048387096774, "accuracy_n": 992, "auc": 0.8881048387096774}}
{"key": "result_239", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9346076458752515, "accuracy_n": 994, "auc": 0.9346076458752515}}
{"key": "result_240", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8703517587939699, "accuracy_n": 995, "auc": 0.8703517587939699}}
{"key": "result_241", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.942713567839196, "accuracy_n": 995, "auc": 0.942713567839196}}
{"key": "result_242", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8303249097472925, "accuracy_n": 277, "auc": 0.8303249097472925}}
{"key": "result_243", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.62, "accuracy_n": 100, "auc": 0.62}}
{"key": "result_244", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8462311557788945, "accuracy_n": 995, "auc": 0.8462311557788945}}
{"key": "result_245", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.687374749498998, "accuracy_n": 499, "auc": 0.687374749498998}}
{"key": "result_246", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7088353413654619, "accuracy_n": 498, "auc": 0.7088353413654619}}
{"key": "result_247", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7591973244147158, "accuracy_n": 299, "auc": 0.7591973244147158}}
{"key": "result_248", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9295774647887324, "accuracy_n": 497, "auc": 0.9295774647887324}}
{"key": "result_249", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7412060301507538, "accuracy_n": 398, "auc": 0.7412060301507538}}
{"key": "result_250", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.976897689768977, "accuracy_n": 303, "auc": 0.976897689768977}}
{"key": "result_251", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8793103448275862, "accuracy_n": 58, "auc": 0.8793103448275862}}
{"key": "result_252", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9683734939759037, "accuracy_n": 322, "auc": 0.9683734939759037}}
{"key": "result_253", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8210056390977443, "accuracy_n": 292, "auc": 0.8210056390977443}}
{"key": "result_254", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_conj", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_255", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9243951612903226, "accuracy_n": 992, "auc": 0.9243951612903226}}
{"key": "result_256", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9436619718309859, "accuracy_n": 994, "auc": 0.9436619718309859}}
{"key": "result_257", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9165829145728643, "accuracy_n": 995, "auc": 0.9165829145728643}}
{"key": "result_258", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.985929648241206, "accuracy_n": 995, "auc": 0.985929648241206}}
{"key": "result_259", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8339350180505415, "accuracy_n": 277, "auc": 0.8339350180505415}}
{"key": "result_260", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.83, "accuracy_n": 100, "auc": 0.83}}
{"key": "result_261", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8160804020100503, "accuracy_n": 995, "auc": 0.8160804020100503}}
{"key": "result_262", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6993987975951904, "accuracy_n": 499, "auc": 0.6993987975951904}}
{"key": "result_263", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7530120481927711, "accuracy_n": 498, "auc": 0.7530120481927711}}
{"key": "result_264", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7692307692307693, "accuracy_n": 299, "auc": 0.7692307692307693}}
{"key": "result_265", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9336016096579477, "accuracy_n": 497, "auc": 0.9336016096579477}}
{"key": "result_266", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7613065326633166, "accuracy_n": 398, "auc": 0.7613065326633166}}
{"key": "result_267", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.966996699669967, "accuracy_n": 303, "auc": 0.966996699669967}}
{"key": "result_268", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8793103448275862, "accuracy_n": 58, "auc": 0.8793103448275862}}
{"key": "result_269", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9518844609206054, "accuracy_n": 322, "auc": 0.9518844609206054}}
{"key": "result_270", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9294642857142857, "accuracy_n": 292, "auc": 0.9294642857142857}}
{"key": "result_271", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_cities_cities_disj", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
{"key": "result_272", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "imdb", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9173387096774194, "accuracy_n": 992, "auc": 0.9173387096774194}}
{"key": "result_273", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "amazon_polarity", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9446680080482898, "accuracy_n": 994, "auc": 0.9446680080482898}}
{"key": "result_274", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "ag_news", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.892462311557789, "accuracy_n": 995, "auc": 0.892462311557789}}
{"key": "result_275", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "dbpedia_14", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.985929648241206, "accuracy_n": 995, "auc": 0.985929648241206}}
{"key": "result_276", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "rte", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7978339350180506, "accuracy_n": 277, "auc": 0.7978339350180506}}
{"key": "result_277", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "copa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.62, "accuracy_n": 100, "auc": 0.62}}
{"key": "result_278", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "boolq", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8160804020100503, "accuracy_n": 995, "auc": 0.8160804020100503}}
{"key": "result_279", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "open_book_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6312625250501002, "accuracy_n": 499, "auc": 0.6312625250501002}}
{"key": "result_280", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "race", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.6987951807228916, "accuracy_n": 498, "auc": 0.6987951807228916}}
{"key": "result_281", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "arc_challenge", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7759197324414716, "accuracy_n": 299, "auc": 0.7759197324414716}}
{"key": "result_282", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "arc_easy", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9295774647887324, "accuracy_n": 497, "auc": 0.9295774647887324}}
{"key": "result_283", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "common_sense_qa", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.7236180904522613, "accuracy_n": 398, "auc": 0.7236180904522613}}
{"key": "result_284", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "got_cities", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9735973597359736, "accuracy_n": 303, "auc": 0.9735973597359736}}
{"key": "result_285", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "got_sp_en_trans", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8793103448275862, "accuracy_n": 58, "auc": 0.8793103448275862}}
{"key": "result_286", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "got_cities_cities_conj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9564025332097622, "accuracy_n": 322, "auc": 0.9564025332097622}}
{"key": "result_287", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "got_cities_cities_disj", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.8160714285714286, "accuracy_n": 292, "auc": 0.8160714285714286}}
{"key": "result_288", "value": {"llm_id": "Qwen/Qwen3-4B", "train_dataset": "got_larger_than", "eval_dataset": "got_larger_than", "probe_method": "dim", "point_name": "h27", "token_idx": -1, "accuracy": 0.9951456310679612, "accuracy_n": 412, "auc": 0.9951456310679612}}
